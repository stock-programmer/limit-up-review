"""
LLMå®¢æˆ·ç«¯
æ”¯æŒå¤šç§å¤§è¯­è¨€æ¨¡å‹APIè¿›è¡Œè´¢åŠ¡æŠ¥å‘Šåˆ†æ
"""

import os
import json
import base64
import time
from typing import Dict, Optional, Any, List
import requests
from abc import ABC, abstractmethod
try:
    import google.generativeai as genai
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
except ImportError:
    genai = None


class BaseLLMClient(ABC):
    """LLMå®¢æˆ·ç«¯åŸºç±»"""
    
    @abstractmethod
    def analyze_text(self, text: str, prompt: str) -> str:
        """åˆ†ææ–‡æœ¬å†…å®¹"""
        pass
    
    @abstractmethod
    def analyze_pdf_directly(self, pdf_path: str, prompt: str) -> str:
        """ç›´æ¥åˆ†æPDFæ–‡ä»¶ï¼ˆå¦‚æœAPIæ”¯æŒï¼‰"""
        pass


class OpenAIClient(BaseLLMClient):
    """OpenAI GPTå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.openai.com/v1", model: str = "gpt-4o"):
        """
        åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        
        Args:
            api_key (str): OpenAI APIå¯†é’¥
            base_url (str): APIåŸºç¡€URL
            model (str): æ¨¡å‹åç§°
        """
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def analyze_text(self, text: str, prompt: str) -> str:
        """
        åˆ†ææ–‡æœ¬å†…å®¹
        
        Args:
            text (str): æ–‡æœ¬å†…å®¹
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        try:
            messages = [
                {"role": "system", "content": prompt},
                {"role": "user", "content": text}
            ]
            
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": 0.1,
                "max_tokens": 4000
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                raise Exception(f"OpenAI APIé”™è¯¯: {response.status_code}, {response.text}")
                
        except Exception as e:
            print(f"OpenAIåˆ†ææ–‡æœ¬å¤±è´¥: {e}")
            return ""
    
    def analyze_pdf_directly(self, pdf_path: str, prompt: str) -> str:
        """
        ç›´æ¥åˆ†æPDFæ–‡ä»¶ï¼ˆGPT-4Væ”¯æŒï¼‰
        
        Args:
            pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        try:
            # å°†PDFè½¬æ¢ä¸ºbase64
            with open(pdf_path, "rb") as pdf_file:
                pdf_base64 = base64.b64encode(pdf_file.read()).decode()
            
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:application/pdf;base64,{pdf_base64}"
                            }
                        }
                    ]
                }
            ]
            
            payload = {
                "model": "gpt-4o",  # ä½¿ç”¨æ”¯æŒæ–‡ä»¶ä¸Šä¼ çš„æ¨¡å‹
                "messages": messages,
                "temperature": 0.1,
                "max_tokens": 4000
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=payload,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                print(f"PDFç›´æ¥åˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬åˆ†æ: {response.status_code}")
                # é™çº§åˆ°æ–‡æœ¬åˆ†æ
                return ""
                
        except Exception as e:
            print(f"OpenAIç›´æ¥åˆ†æPDFå¤±è´¥: {e}")
            return ""


class ClaudeClient(BaseLLMClient):
    """Claudeå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.anthropic.com", model: str = "claude-3-sonnet-20240229"):
        """
        åˆå§‹åŒ–Claudeå®¢æˆ·ç«¯
        
        Args:
            api_key (str): Claude APIå¯†é’¥
            base_url (str): APIåŸºç¡€URL
            model (str): æ¨¡å‹åç§°
        """
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.headers = {
            "x-api-key": api_key,
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01"
        }
    
    def analyze_text(self, text: str, prompt: str) -> str:
        """
        åˆ†ææ–‡æœ¬å†…å®¹
        
        Args:
            text (str): æ–‡æœ¬å†…å®¹
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        try:
            payload = {
                "model": self.model,
                "max_tokens": 4000,
                "temperature": 0.1,
                "messages": [
                    {
                        "role": "user",
                        "content": f"{prompt}\n\nä»¥ä¸‹æ˜¯éœ€è¦åˆ†æçš„è´¢åŠ¡æŠ¥å‘Šå†…å®¹:\n{text}"
                    }
                ]
            }
            
            response = requests.post(
                f"{self.base_url}/v1/messages",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["content"][0]["text"]
            else:
                raise Exception(f"Claude APIé”™è¯¯: {response.status_code}, {response.text}")
                
        except Exception as e:
            print(f"Claudeåˆ†ææ–‡æœ¬å¤±è´¥: {e}")
            return ""
    
    def analyze_pdf_directly(self, pdf_path: str, prompt: str) -> str:
        """Claudeç›®å‰ä¸æ”¯æŒç›´æ¥PDFåˆ†æ"""
        print("Claudeæš‚ä¸æ”¯æŒç›´æ¥PDFåˆ†æï¼Œè¯·ä½¿ç”¨æ–‡æœ¬åˆ†æ")
        return ""


class GeminiClient(BaseLLMClient):
    """Google Geminiå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = "https://generativelanguage.googleapis.com/v1beta", model: str = "gemini-1.5-pro"):
        """
        åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        
        Args:
            api_key (str): Google Gemini APIå¯†é’¥
            base_url (str): APIåŸºç¡€URL (ä»…ç”¨äºå…¼å®¹æ€§ï¼Œå®˜æ–¹SDKä¼šè‡ªåŠ¨å¤„ç†)
            model (str): æ¨¡å‹åç§°
        """
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.headers = {"Content-Type": "application/json"}
        
        # é…ç½®ä»£ç†ï¼ˆå¦‚æœè®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼‰
        self.proxy_config = self._setup_proxy()
        
        # å°è¯•ä½¿ç”¨å®˜æ–¹SDK
        self.use_official_sdk = genai is not None
        if self.use_official_sdk:
            try:
                # é…ç½®å®˜æ–¹SDK
                genai.configure(api_key=api_key)
                
                # é…ç½®å®‰å…¨è®¾ç½® - é™ä½å®‰å…¨é™åˆ¶ä»¥å‡å°‘è¢«é˜»æ­¢çš„å¯èƒ½æ€§
                self.safety_settings = {
                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                }
                
                # åˆå§‹åŒ–æ¨¡å‹
                self.genai_model = genai.GenerativeModel(
                    model_name=self.model,
                    safety_settings=self.safety_settings
                )
                print(f"ä½¿ç”¨Googleå®˜æ–¹SDKåˆå§‹åŒ–Geminiå®¢æˆ·ç«¯æˆåŠŸ: {model}")
            except Exception as e:
                print(f"å®˜æ–¹SDKåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨HTTPè¯·æ±‚: {e}")
                self.use_official_sdk = False
        else:
            print("Google GenerativeAI SDKæœªå®‰è£…ï¼Œä½¿ç”¨HTTPè¯·æ±‚")
    
    def _setup_proxy(self) -> Dict[str, str]:
        """è®¾ç½®ä»£ç†é…ç½®"""
        proxy_config = {}
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†é…ç½®
        http_proxy = os.getenv('HTTP_PROXY') or os.getenv('http_proxy')
        https_proxy = os.getenv('HTTPS_PROXY') or os.getenv('https_proxy')
        
        if http_proxy:
            proxy_config['http'] = http_proxy
        if https_proxy:
            proxy_config['https'] = https_proxy
            
        return proxy_config
    
    def _retry_with_backoff(self, func, max_retries: int = 3, initial_delay: float = 1.0):
        """å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶"""
        for attempt in range(max_retries):
            try:
                return func()
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                    
                delay = initial_delay * (2 ** attempt)
                print(f"è¯·æ±‚å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries}): {str(e)[:100]}")
                time.sleep(delay)
    
    def analyze_text(self, text: str, prompt: str) -> str:
        """
        åˆ†ææ–‡æœ¬å†…å®¹
        
        Args:
            text (str): æ–‡æœ¬å†…å®¹
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        # ä½¿ç”¨å®˜æ–¹SDK
        if self.use_official_sdk:
            return self._analyze_text_with_sdk(text, prompt)
        
        # é™çº§åˆ°HTTPè¯·æ±‚
        return self._analyze_text_with_http(text, prompt)
    
    def _analyze_text_with_sdk(self, text: str, prompt: str) -> str:
        """ä½¿ç”¨å®˜æ–¹SDKåˆ†ææ–‡æœ¬"""
        try:
            def make_request():
                full_prompt = f"{prompt}\n\nä»¥ä¸‹æ˜¯éœ€è¦åˆ†æçš„è´¢åŠ¡æŠ¥å‘Šå†…å®¹:\n{text}"
                
                # é…ç½®ç”Ÿæˆå‚æ•°
                generation_config = {
                    'temperature': 0.1,
                    'max_output_tokens': 4000,
                }
                
                response = self.genai_model.generate_content(
                    full_prompt,
                    generation_config=generation_config
                )
                
                if response.text:
                    return response.text
                elif response.candidates:
                    return response.candidates[0].content.parts[0].text
                else:
                    raise Exception(f"Gemini SDKå“åº”ä¸ºç©º: {response}")
            
            return self._retry_with_backoff(make_request, max_retries=3)
            
        except Exception as e:
            print(f"Gemini SDKåˆ†ææ–‡æœ¬å¤±è´¥: {e}")
            # å°è¯•é™çº§åˆ°HTTPè¯·æ±‚
            print("å°è¯•é™çº§åˆ°HTTPè¯·æ±‚...")
            return self._analyze_text_with_http(text, prompt)
    
    def _analyze_text_with_http(self, text: str, prompt: str) -> str:
        """ä½¿ç”¨HTTPè¯·æ±‚åˆ†ææ–‡æœ¬"""
        try:
            def make_request():
                payload = {
                    "contents": [{
                        "parts": [{
                            "text": f"{prompt}\n\nä»¥ä¸‹æ˜¯éœ€è¦åˆ†æçš„è´¢åŠ¡æŠ¥å‘Šå†…å®¹:\n{text}"
                        }]
                    }],
                    "generationConfig": {
                        "temperature": 0.1,
                        "maxOutputTokens": 4000
                    },
                    "safetySettings": [
                        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
                    ]
                }
                
                # å°è¯•å¤šä¸ªAPIç«¯ç‚¹
                endpoints = [
                    f"{self.base_url}/models/{self.model}:generateContent?key={self.api_key}",
                    f"https://generativelanguage.googleapis.com/v1/models/{self.model}:generateContent?key={self.api_key}",
                    f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}"
                ]
                
                last_error = None
                for endpoint in endpoints:
                    try:
                        # å‡†å¤‡è¯·æ±‚å‚æ•°
                        request_kwargs = {
                            'headers': self.headers,
                            'json': payload,
                            'timeout': 120  # å¢åŠ è¶…æ—¶æ—¶é—´
                        }
                        
                        # å¦‚æœé…ç½®äº†ä»£ç†ï¼Œæ·»åŠ ä»£ç†è®¾ç½®
                        if self.proxy_config:
                            request_kwargs['proxies'] = self.proxy_config
                            print(f"ä½¿ç”¨ä»£ç†: {self.proxy_config}")
                        
                        response = requests.post(endpoint, **request_kwargs)
                        
                        if response.status_code == 200:
                            result = response.json()
                            if "candidates" in result and result["candidates"]:
                                return result["candidates"][0]["content"]["parts"][0]["text"]
                            else:
                                raise Exception(f"Gemini APIå“åº”æ ¼å¼é”™è¯¯: {result}")
                        else:
                            raise Exception(f"HTTP {response.status_code}: {response.text}")
                            
                    except Exception as e:
                        last_error = e
                        print(f"ç«¯ç‚¹ {endpoint} è¯·æ±‚å¤±è´¥: {e}")
                        continue
                        
                raise last_error or Exception("æ‰€æœ‰APIç«¯ç‚¹éƒ½æ— æ³•è®¿é—®")
            
            return self._retry_with_backoff(make_request, max_retries=2)
            
        except Exception as e:
            print(f"Gemini HTTPåˆ†ææ–‡æœ¬å¤±è´¥: {e}")
            return ""
    
    def analyze_pdf_directly(self, pdf_path: str, prompt: str) -> str:
        """
        ç›´æ¥åˆ†æPDFæ–‡ä»¶ï¼ˆGeminiæ”¯æŒæ–‡ä»¶ä¸Šä¼ ï¼‰
        
        Args:
            pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        # ä½¿ç”¨å®˜æ–¹SDK
        if self.use_official_sdk:
            return self._analyze_pdf_with_sdk(pdf_path, prompt)
        
        # é™çº§åˆ°HTTPè¯·æ±‚
        return self._analyze_pdf_with_http(pdf_path, prompt)
    
    def _analyze_pdf_with_sdk(self, pdf_path: str, prompt: str) -> str:
        """ä½¿ç”¨å®˜æ–¹SDKåˆ†æPDF"""
        try:
            def make_request():
                # ä¸Šä¼ æ–‡ä»¶åˆ°Gemini
                uploaded_file = genai.upload_file(pdf_path)
                print(f"PDFæ–‡ä»¶å·²ä¸Šä¼ : {uploaded_file.name}")
                
                try:
                    # ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ
                    while uploaded_file.state.name == "PROCESSING":
                        print("æ­£åœ¨å¤„ç†PDFæ–‡ä»¶...")
                        time.sleep(2)
                        uploaded_file = genai.get_file(uploaded_file.name)
                    
                    if uploaded_file.state.name == "FAILED":
                        raise Exception(f"PDFæ–‡ä»¶å¤„ç†å¤±è´¥: {uploaded_file.state}")
                    
                    # ç”Ÿæˆå†…å®¹
                    response = self.genai_model.generate_content(
                        [prompt, uploaded_file],
                        generation_config={'temperature': 0.1, 'max_output_tokens': 4000}
                    )
                    
                    if response.text:
                        return response.text
                    elif response.candidates:
                        return response.candidates[0].content.parts[0].text
                    else:
                        raise Exception(f"Gemini SDK PDFå“åº”ä¸ºç©º: {response}")
                        
                finally:
                    # æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶
                    try:
                        genai.delete_file(uploaded_file.name)
                        print("å·²æ¸…ç†ä¸Šä¼ çš„PDFæ–‡ä»¶")
                    except:
                        pass
            
            return self._retry_with_backoff(make_request, max_retries=2)
            
        except Exception as e:
            print(f"Gemini SDKåˆ†æPDFå¤±è´¥: {e}")
            # å°è¯•é™çº§åˆ°HTTPè¯·æ±‚
            print("å°è¯•é™çº§åˆ°HTTPè¯·æ±‚...")
            return self._analyze_pdf_with_http(pdf_path, prompt)
    
    def _analyze_pdf_with_http(self, pdf_path: str, prompt: str) -> str:
        """ä½¿ç”¨HTTPè¯·æ±‚åˆ†æPDF"""
        try:
            import base64
            
            def make_request():
                # å°†PDFè½¬æ¢ä¸ºbase64
                with open(pdf_path, "rb") as pdf_file:
                    pdf_base64 = base64.b64encode(pdf_file.read()).decode()
                
                payload = {
                    "contents": [{
                        "parts": [
                            {"text": prompt},
                            {
                                "inline_data": {
                                    "mime_type": "application/pdf",
                                    "data": pdf_base64
                                }
                            }
                        ]
                    }],
                    "generationConfig": {
                        "temperature": 0.1,
                        "maxOutputTokens": 4000
                    },
                    "safetySettings": [
                        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
                    ]
                }
                
                # å°è¯•å¤šä¸ªAPIç«¯ç‚¹
                endpoints = [
                    f"{self.base_url}/models/{self.model}:generateContent?key={self.api_key}",
                    f"https://generativelanguage.googleapis.com/v1/models/{self.model}:generateContent?key={self.api_key}",
                    f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}"
                ]
                
                last_error = None
                for endpoint in endpoints:
                    try:
                        request_kwargs = {
                            'headers': self.headers,
                            'json': payload,
                            'timeout': 180  # PDFå¤„ç†éœ€è¦æ›´é•¿æ—¶é—´
                        }
                        
                        if self.proxy_config:
                            request_kwargs['proxies'] = self.proxy_config
                        
                        response = requests.post(endpoint, **request_kwargs)
                        
                        if response.status_code == 200:
                            result = response.json()
                            if "candidates" in result and result["candidates"]:
                                return result["candidates"][0]["content"]["parts"][0]["text"]
                            else:
                                raise Exception(f"PDFåˆ†æå“åº”æ ¼å¼é”™è¯¯: {result}")
                        else:
                            raise Exception(f"HTTP {response.status_code}: {response.text}")
                            
                    except Exception as e:
                        last_error = e
                        print(f"PDFç«¯ç‚¹ {endpoint} è¯·æ±‚å¤±è´¥: {e}")
                        continue
                        
                raise last_error or Exception("æ‰€æœ‰PDF APIç«¯ç‚¹éƒ½æ— æ³•è®¿é—®")
            
            return self._retry_with_backoff(make_request, max_retries=1)
            
        except Exception as e:
            print(f"Gemini HTTPç›´æ¥åˆ†æPDFå¤±è´¥: {e}")
            return ""


class LocalLLMClient(BaseLLMClient):
    """æœ¬åœ°LLMå®¢æˆ·ç«¯ï¼ˆå¦‚Ollamaï¼‰"""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "qwen2.5:14b"):
        """
        åˆå§‹åŒ–æœ¬åœ°LLMå®¢æˆ·ç«¯
        
        Args:
            base_url (str): æœ¬åœ°LLM APIåœ°å€
            model (str): æ¨¡å‹åç§°
        """
        self.base_url = base_url
        self.model = model
        self.headers = {"Content-Type": "application/json"}
    
    def analyze_text(self, text: str, prompt: str) -> str:
        """
        åˆ†ææ–‡æœ¬å†…å®¹
        
        Args:
            text (str): æ–‡æœ¬å†…å®¹
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        try:
            payload = {
                "model": self.model,
                "prompt": f"{prompt}\n\nä»¥ä¸‹æ˜¯éœ€è¦åˆ†æçš„è´¢åŠ¡æŠ¥å‘Šå†…å®¹:\n{text}",
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "num_predict": 4000
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/generate",
                headers=self.headers,
                json=payload,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "")
            else:
                raise Exception(f"æœ¬åœ°LLM APIé”™è¯¯: {response.status_code}, {response.text}")
                
        except Exception as e:
            print(f"æœ¬åœ°LLMåˆ†ææ–‡æœ¬å¤±è´¥: {e}")
            return ""
    
    def analyze_pdf_directly(self, pdf_path: str, prompt: str) -> str:
        """æœ¬åœ°LLMé€šå¸¸ä¸æ”¯æŒç›´æ¥PDFåˆ†æ"""
        print("æœ¬åœ°LLMæš‚ä¸æ”¯æŒç›´æ¥PDFåˆ†æï¼Œè¯·ä½¿ç”¨æ–‡æœ¬åˆ†æ")
        return ""


class LLMClient:
    """LLMå®¢æˆ·ç«¯ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ç®¡ç†å™¨"""
        self.clients = {}
        self.active_client = None
        self._setup_clients()
    
    def _setup_clients(self):
        """è®¾ç½®å¯ç”¨çš„LLMå®¢æˆ·ç«¯"""
        # å°è¯•è®¾ç½®OpenAIå®¢æˆ·ç«¯
        openai_key = os.getenv('OPENAI_API_KEY')
        openai_base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
        if openai_key:
            self.clients['openai'] = OpenAIClient(openai_key, openai_base_url)
            print("OpenAIå®¢æˆ·ç«¯å·²é…ç½®")
        
        # å°è¯•è®¾ç½®Claudeå®¢æˆ·ç«¯
        claude_key = os.getenv('CLAUDE_API_KEY')
        if claude_key:
            self.clients['claude'] = ClaudeClient(claude_key)
            print("Claudeå®¢æˆ·ç«¯å·²é…ç½®")
        
        # å°è¯•è®¾ç½®Geminiå®¢æˆ·ç«¯
        gemini_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
        if gemini_key:
            try:
                self.clients['gemini'] = GeminiClient(gemini_key)
                print("Geminiå®¢æˆ·ç«¯å·²é…ç½®")
            except Exception as e:
                print(f"Geminiå®¢æˆ·ç«¯é…ç½®å¤±è´¥: {e}")
                print("ğŸ’¡ å¦‚é‡ç½‘ç»œé—®é¢˜ï¼Œè¯·å‚è€ƒ NETWORK_TROUBLESHOOTING.md")
        
        # å°è¯•è®¾ç½®æœ¬åœ°LLMå®¢æˆ·ç«¯
        local_url = os.getenv('LOCAL_LLM_URL', 'http://localhost:11434')
        try:
            # æµ‹è¯•æœ¬åœ°LLMè¿æ¥
            response = requests.get(f"{local_url}/api/tags", timeout=5)
            if response.status_code == 200:
                self.clients['local'] = LocalLLMClient(local_url)
                print("æœ¬åœ°LLMå®¢æˆ·ç«¯å·²é…ç½®")
        except:
            pass
        
        # è®¾ç½®é»˜è®¤å®¢æˆ·ç«¯
        if 'openai' in self.clients:
            self.active_client = self.clients['openai']
            print("ä½¿ç”¨OpenAIä½œä¸ºé»˜è®¤å®¢æˆ·ç«¯")
        elif 'gemini' in self.clients:
            self.active_client = self.clients['gemini']
            print("ä½¿ç”¨Geminiä½œä¸ºé»˜è®¤å®¢æˆ·ç«¯")
        elif 'claude' in self.clients:
            self.active_client = self.clients['claude']
            print("ä½¿ç”¨Claudeä½œä¸ºé»˜è®¤å®¢æˆ·ç«¯")
        elif 'local' in self.clients:
            self.active_client = self.clients['local']
            print("ä½¿ç”¨æœ¬åœ°LLMä½œä¸ºé»˜è®¤å®¢æˆ·ç«¯")
        else:
            print("è­¦å‘Š: æœªé…ç½®ä»»ä½•LLMå®¢æˆ·ç«¯ï¼Œè¯·è®¾ç½®APIå¯†é’¥")
    
    def set_active_client(self, client_name: str) -> bool:
        """
        è®¾ç½®æ´»è·ƒå®¢æˆ·ç«¯
        
        Args:
            client_name (str): å®¢æˆ·ç«¯åç§° ('openai', 'claude', 'gemini', 'local')
            
        Returns:
            bool: è®¾ç½®æ˜¯å¦æˆåŠŸ
        """
        if client_name in self.clients:
            self.active_client = self.clients[client_name]
            print(f"å·²åˆ‡æ¢åˆ° {client_name} å®¢æˆ·ç«¯")
            return True
        else:
            print(f"å®¢æˆ·ç«¯ {client_name} ä¸å­˜åœ¨æˆ–æœªé…ç½®")
            return False
    
    def analyze_text(self, text: str, prompt: str) -> str:
        """
        ä½¿ç”¨æ´»è·ƒå®¢æˆ·ç«¯åˆ†ææ–‡æœ¬
        
        Args:
            text (str): æ–‡æœ¬å†…å®¹
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        if not self.active_client:
            raise Exception("æœªé…ç½®ä»»ä½•LLMå®¢æˆ·ç«¯ï¼Œè¯·è®¾ç½®APIå¯†é’¥")
        
        return self.active_client.analyze_text(text, prompt)
    
    def analyze_pdf_directly(self, pdf_path: str, prompt: str) -> str:
        """
        ä½¿ç”¨æ´»è·ƒå®¢æˆ·ç«¯ç›´æ¥åˆ†æPDF
        
        Args:
            pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        if not self.active_client:
            raise Exception("æœªé…ç½®ä»»ä½•LLMå®¢æˆ·ç«¯ï¼Œè¯·è®¾ç½®APIå¯†é’¥")
        
        return self.active_client.analyze_pdf_directly(pdf_path, prompt)
    
    def get_available_clients(self) -> List[str]:
        """
        è·å–å¯ç”¨å®¢æˆ·ç«¯åˆ—è¡¨
        
        Returns:
            List[str]: å¯ç”¨å®¢æˆ·ç«¯åç§°åˆ—è¡¨
        """
        return list(self.clients.keys())
    
    def is_configured(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰é…ç½®çš„å®¢æˆ·ç«¯
        
        Returns:
            bool: æ˜¯å¦æœ‰å¯ç”¨å®¢æˆ·ç«¯
        """
        return self.active_client is not None